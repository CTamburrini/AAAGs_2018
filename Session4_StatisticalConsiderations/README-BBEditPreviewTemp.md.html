<h2>Part 0: Data Read-in</h2>



<pre><code>rawgenos &amp;lt;- read.table(file="Consolidated Genotypes.csv", header = TRUE, sep=",", row.names = 1) snpinfo &amp;lt;- read.table(file="SNPinfo.csv", header = TRUE, sep=",") pheno &amp;lt;- read.table(file="pheno.csv", header = TRUE, sep=",",row.names = 1)
</code></pre>



<h2>Part 1: mini-GWAS and Basic Bonferroni Correction</h2>

<h3>Package install</h3>

<p>Answer y when asked whether to install from a source that needs compilation</p>



<pre><code>install.packages("SNPassoc") library(SNPassoc)
</code></pre>



<h3>Format data for SNPassoc (similar to PLINK format)</h3>



<pre><code>geno\_pheno&amp;lt;-cbind(pheno,rawgenos) org\_geno&amp;lt;-setupSNP(geno\_pheno, 4:ncol(geno\_pheno), sort = TRUE, snpinfo, sep = "")
</code></pre>



<p>Check that setup worked (wouldn't recommend doing this w/o row specification)</p>



<pre><code>summary(org\_geno\[,4:8\]) plot(org\_geno,which=13)
</code></pre>



<h3>Run the mini-GWAS</h3>



<pre><code>suborg\_geno&amp;lt;-org\_geno\[,1:1000\]

start\_time &amp;lt;- Sys.time() \#This next line of code is all you really need, start and end times are just for reference. \#You purposely leave the SNP out of the equation as part of how this function works. miniGWAS&amp;lt;-WGassociation(birthweight\_kg~1, suborg\_geno, model = "codominant", genotypingRate = 80) end\_time &amp;lt;- Sys.time() end\_time - start\_time

Bonferroni.sig(miniGWAS, model = "codominant", alpha = 0.05) plot(miniGWAS)
</code></pre>



<p>BONUS: If you wanted to include covariates, you would simply replace the 1 in the minigwas</p>

<p>with the name of the covariate. If you want to try you can add the covariate 'trauma' to</p>

<p>the model, which I've included in column 3 of suborg_geno if you examine it.</p>

<h2>Part 2: Testing Using Simple M</h2>

<p>Useful citations for this:</p>

<p>Gao X, Starmer J, and Martin ER. (2008). A multiple testing correction method for genetic association studies using correlated single nucleotide polymorphisms. Genetic Epidemiology, 32, 361-369.</p>

<p>Johnson RC, Nelson GW, Troyer JL, Lautenberger JA, Kessing BD, Winkler CA, and O'Brien SJ. (2010). Accounting for multiple comparisons in a genome-wide association study (GWAS).BMC Genomics, 11, 724-724.</p>

<h3>Convert the genotypes to numeric values</h3>



<pre><code>mgenos&amp;lt;-rawgenos for(n in 1:ncol(mgenos)){ mgenos\[,n\]&amp;lt;-as.numeric(mgenos\[,n\])-1 }
</code></pre>



<h3>Compute the Composite Linkage Disequilibrium Score</h3>

<p>The commented out line will likely not work with a larger dataset due to lack of RAM.</p>

<p>However, I am including it for illustration purposes as its the first thing many think of</p>

<p>and even the papers above recommend using this function, but dont adress this difficulty.</p>



<pre><code>compld&amp;lt;-cor(mgenos)
</code></pre>



<p>In light of this, you usually need to break the data up into ~5,000 SNP chunks.</p>

<p>Ideally, you would do this based on haplotype blocks with haploview, but since our</p>

<p>data is small, we'll just separate it by chromosome. We'll do chromosome 10 as an example.</p>



<pre><code>n&amp;lt;-10 chromsnps&amp;lt;-snpinfo$Chromosome == n \#If you want to know how many SNPs that is use sum(chromsnps ==TRUE) compld&amp;lt;-cor(mgenos\[,chromsnps\], use= "complete.obs")
</code></pre>



<p>Always a good idea to inspect the matrix</p>



<pre><code>compld\[1:10,1:10\]
</code></pre>



<p>There are snps without enough variance so they'll need to be removed. The fact they have</p>

<p>so little variance means they couldn't be tested anyway meaning they don't contribute to</p>

<p>the multiple testing burden.</p>



<pre><code>newcompld&amp;lt;-compld\[is.na(compld\[,1\]) == FALSE, is.na(compld\[,1\]) == FALSE\]
</code></pre>



<h3>Calculate the Eigenvalues</h3>



<pre><code>eigns&amp;lt;-eigen(newcompld, only.values = TRUE)
</code></pre>



<p>We now need to add the eigenvalues together until we reach 99.5% of the variance and count</p>

<p>how many that takes. The total variance in this case is the sum of the number of variables.</p>

<p>Keep in mind this number is going to be very low because we have so few samples. With a</p>

<p>normal genomics study you would want many more and you'd need to worry about things like</p>

<p>population structure, which we ignored in our miniGWAS, but are likely reflected here.</p>



<pre><code>thresholdvar&amp;lt;-ncol(newcompld)\*.995 eigentotal&amp;lt;-0 counter&amp;lt;-0 for (v in 1:length(eigns$values)){  if(eigentotal&amp;lt;thresholdvar){  counter&amp;lt;-counter + 1  eigentotal&amp;lt;-eigentotal + eigns$values\[v\] } }

print(counter)
</code></pre>



<p>This would then be repeated for each chromosome and you would add the values togerther</p>

<p>to get the total number of tests to apply Bonferroni correction. Try it with chromosome 1</p>

<p>and be sure to inspect the corrlation matrix before removing bad SNPs as there is a trap!</p>

<h2>Part 3: Basic FDR Correction</h2>

<p>Extract the p-values from our earlier mini-GWAS</p>



<pre><code>pvaladd&amp;lt;-codominant(miniGWAS)
</code></pre>



<p>Check if FDR is appropriate</p>



<pre><code>hist(pvaladd, breaks = 20)
</code></pre>



<p>Since the historam is relatively uniform, by strictest standards we shouldn't be using</p>

<p>FDR here, but well keep going for demonstration purposes</p>

<p>qvals&lt;-p.adjust(pvaladd, "fdr")</p>

<p>Since we only did 1000 SNPs, this is small enough to look at directly.</p>



<pre><code>hist(qvals, xlim = 0:1)
</code></pre>



<p>Clearly there is nothing significant in this case, which is to be expected based on the</p>

<p>histogram and sample size. Just to confirm:</p>



<pre><code>sum(qvals &amp;lt; 0.05, na.rm = TRUE)
</code></pre>



<h2>Part 4: Empirical P-values using Reshuffling (Permutation Testing)</h2>

<p>We're going to use a method called max(T) permutation where we take the lowest p-value from</p>

<p>testing each reshuffle against the simulated phenotype. Not necessarily the most efficient,</p>

<p>but certainly valid under the majority of circumstances.</p>

<h3>Simulate p-values and generate empirical ones</h3>



<pre><code>n\_sims&amp;lt;-40 simoutputGWAS&amp;lt;-NULL
</code></pre>



<p>system timer so we can see how long it takes</p>



<pre><code>start\_time\_sim &amp;lt;- Sys.time()

for (n in 1:n\_sims){ \#Create a new object to simulate the dataset (might need to modify original if larger) sim\_suborg\_geno&amp;lt;-suborg\_geno

\#Shuffle the phenotype row order using the sample function newrowindex&amp;lt;-sample(nrow(sim\_suborg\_geno), nrow(sim\_suborg\_geno))

\#Use the new row order to assign phenotypes sim\_suborg\_geno\[,1\]&amp;lt;-as.data.frame(as.matrix(sim\_suborg\_geno\[newrowindex,1\]))

\#Run the mini-GWAS sim\_miniGWAS&amp;lt;-WGassociation(birthweight\_kg~1, sim\_suborg\_geno, model = "codominant", genotypingRate = 80)

\#Extract the pvalues sim\_pvals&amp;lt;-codominant(sim\_miniGWAS)

\#Take the smallest p-value and save it simoutputGWAS\[n\]&amp;lt;-min(sim\_pvals, na.rm = TRUE)

}
</code></pre>



<p>Generate empirical p-values by comparing to the simulated ones</p>



<pre><code>permutedpvals&amp;lt;-NULL for (c in 1:length(pvaladd)){ n\_nonsig&amp;lt;-sum(pvaladd\[c\]&amp;gt;=simoutputGWAS, na.rm = TRUE) permutedpvals\[c\]&amp;lt;-n\_nonsig/n\_sims }
</code></pre>



<p>Check total time it took</p>



<pre><code>end\_time\_sim &amp;lt;- Sys.time() end\_time\_sim - start\_time\_sim
</code></pre>



<h3>See how many SNPs are 'significant'</h3>

<p>See how many SNPs are significant</p>



<pre><code>sum(permutedpvals &amp;lt; 0.05, na.rm = TRUE)
</code></pre>



<p>Get SNP IDs and info</p>



<pre><code>sig\_snps&amp;lt;-which(permutedpvals &amp;lt; 0.05)

sig\_snpIDs&amp;lt;-colnames(suborg\_geno)\[sig\_snps\]

snpinfo\[snpinfo$dbSNP.RS.ID %in% sig\_snpIDs,\] \#NOTE: %in% compares to vectors like == compares to a value
</code></pre>



<p>Permutation gets much more complicated with covariates and you need a lot more planning.</p>

<p>If interested in this, look up the 'BiasedUrn' package.</p>

<h2>Part 5: Basic Parallel Computing</h2>

<p>Detecting the number of cores and setting them up for use</p>



<pre><code>library(doParallel) library(foreach) ncore&amp;lt;-detectCores() cl&amp;lt;-makeCluster(as.numeric(ncore)) registerDoParallel(cl)
</code></pre>



<h3>Define the permutation reshuffles we did as their own function</h3>



<pre><code>permshuffle&amp;lt;-function(genodata, n\_sims) {

simoutputGWAS&amp;lt;-NULL

for (n in 1:n\_sims){

#Create a new object to simulate the dataset (might need to modify original if larger)
sim_suborg_geno&lt;-genodata

#Shuffle the phenotype row order using the sample function
newrowindex&lt;-sample(nrow(sim_suborg_geno), nrow(sim_suborg_geno))

#Use the new row order to assign phenotypes
sim_suborg_geno[,1]&lt;-as.data.frame(as.matrix(sim_suborg_geno[newrowindex,1]))

#Run the mini-GWAS
sim_miniGWAS&lt;-WGassociation(birthweight_kg~1, sim_suborg_geno, model = "codominant", genotypingRate = 80)

#Extract the pvalues
sim_pvals&lt;-codominant(sim_miniGWAS)

#Take the smallest p-value and save it
simoutputGWAS[n]&lt;-min(sim_pvals, na.rm = TRUE)

} simoutputGWAS

}
</code></pre>



<h3>Run the function across multiple cores</h3>

<p>Start time</p>



<pre><code>start\_time\_parasim &amp;lt;- Sys.time()
</code></pre>



<p>Split the simulations among each core and combine the results together</p>

<p>(I changed n_sims because the times 4 means it will end up being 40 and</p>

<p>that splits it evenly across 4 cores).</p>



<pre><code>parallelsimoutput&amp;lt;-foreach(times(4), .combine = "c", .packages="SNPassoc") %dopar% permshuffle(suborg\_geno, n\_sims=10)
</code></pre>



<p>Generate empirical p-values by comparing to the simulated ones</p>



<pre><code>parallelpermutedpvals&amp;lt;-NULL for (c in 1:length(pvaladd)){ n\_nonsig&amp;lt;-sum(pvaladd\[c\]&amp;gt;=parallelsimoutput, na.rm = TRUE) parallelpermutedpvals\[c\]&amp;lt;-n\_nonsig/40 }
</code></pre>



<p>Check total time it took</p>



<pre><code>end\_time\_parasim &amp;lt;- Sys.time() end\_time\_parasim - start\_time\_parasim
</code></pre>



<h3>See how many SNPs are 'significant'</h3>

<p>See how many SNPs are significant</p>



<pre><code>sum(parallelpermutedpvals &amp;lt; 0.05, na.rm = TRUE)
</code></pre>



<p>Get SNP IDs and info</p>



<pre><code>sig\_snps&amp;lt;-which(parallelpermutedpvals &amp;lt; 0.05)

sig\_snpIDs&amp;lt;-colnames(suborg\_geno)\[sig\_snps\]

snpinfo\[snpinfo$dbSNP.RS.ID %in% sig\_snpIDs,\]
</code></pre>



<p>This version of the code is designed mainly for someone with 4 cores, but depending on</p>

<p>how many your setup may have available, other configurations might be better. Feel free</p>

<p>to place with the times() and n_sims options in the foreach line to see how it affects</p>

<p>computing time.</p>
